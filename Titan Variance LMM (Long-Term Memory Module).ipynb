{"cells":[{"cell_type":"markdown","metadata":{"id":"MEd4B_ZKKi12"},"source":["# **LMM (Long-Term Memory Module)**\n","Lets build a tiny LMM (Long-Term Memory Module"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"24s-Ne_9coQ-"},"outputs":[],"source":["import torch\n","import torch.nn as nn"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WoySp6DfcoVp"},"outputs":[],"source":["# VOCAB\n","vocab = [\n","    # Keys\n","    \"user_name\", \"pet_name\", \"favorite_color\", \"city\", \"job\",\n","    \"age\", \"hobby\", \"car\", \"food\", \"sport\",\n","\n","    # Values - Person 1 (Fahad)\n","    \"Fahad\", \"Max\", \"blue\", \"Toronto\", \"engineer\",\n","    \"23\", \"coding\", \"Tesla\", \"biryani\", \"MMA\",\n","\n","    # Values - Person 2 (Alice)\n","    \"Alice\", \"Luna\", \"green\", \"Berlin\", \"designer\",\n","    \"28\", \"painting\", \"BMW\", \"pasta\", \"tennis\",\n","\n","    # Structure\n","    \"is\", \"has\", \"likes\"\n","]\n","\n","word2idx = {w: i for i, w in enumerate(vocab)}\n","idx2word = {i: w for i, w in enumerate(vocab)}\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xs-xyEenQ7Go"},"outputs":[],"source":["# Weights (Frozen)\n","embed = nn.Embedding(len(vocab), 16)\n","embed.weight.requires_grad = False # weights freezed\n","\n","# LMM (BIGGER MLP for more capacity)\n","class LMM(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.net = nn.Sequential(\n","            nn.Linear(16, 128),  # capacity\n","            nn.ReLU(),\n","            nn.Linear(128, 16)\n","        )\n","    def forward(self, x):\n","        return self.net(x)\n","\n","lmm = LMM()\n","optimizer = torch.optim.SGD(lmm.parameters(), lr=0.2)\n","\n","# --- HELPERS ---\n","def word_to_vec(w):\n","    return embed(torch.tensor([word2idx[w]]))\n","\n","def vec_to_word(v):\n","    with torch.no_grad():\n","        dists = torch.norm(embed.weight - v, dim=1)\n","        return idx2word[dists.argmin().item()]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wweMyvPxde8O"},"outputs":[],"source":["# Attention\n","class SimpleAttention(nn.Module):\n","    def __init__(self, dim=16):\n","        super().__init__()\n","        self.query = nn.Linear(dim, dim)\n","        self.key = nn.Linear(dim, dim)\n","        self.value = nn.Linear(dim, dim)\n","\n","    def forward(self, x):\n","        # x shape: (seq_len, dim) or (1, dim)\n","\n","        q = self.query(x)  # (seq_len, dim)\n","        k = self.key(x)    # (seq_len, dim)\n","        v = self.value(x)  # (seq_len, dim)\n","\n","        # FIX: Use transpose instead of .T\n","        scores = torch.matmul(q, k.transpose(-2, -1)) / (16 ** 0.5)\n","\n","        attn_weights = torch.softmax(scores, dim=-1)\n","        output = torch.matmul(attn_weights, v)\n","\n","        return output, attn_weights"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XC2WpaPieW8k"},"outputs":[],"source":["# MAC Layer (combines LMM + Attention)\n","class MAC_Layer(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.lmm = LMM()\n","        self.attention = SimpleAttention(16)\n","\n","    def forward(self, tokens):\n","        # Get memory for each token\n","        memory_vecs = torch.stack([self.lmm(tok) for tok in tokens])\n","\n","        # Combine original + memory\n","        combined = torch.cat([tokens, memory_vecs], dim=0)\n","\n","        # Attention over both\n","        output, weights = self.attention(combined)\n","\n","        return output[:len(tokens)], weights  # Return first half only"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PnJU6agJcy0z"},"outputs":[],"source":["\n","# DATA: INTERLEAVED FACTS\n","base_facts = [\n","    [\"user_name\", \"is\", \"Fahad\"],\n","    [\"pet_name\", \"is\", \"Max\"],\n","    [\"city\", \"is\", \"Toronto\"],\n","    [\"job\", \"is\", \"engineer\"],\n","    [\"favorite_color\", \"is\", \"blue\"],\n","    [\"age\", \"is\", \"23\"],\n","    [\"hobby\", \"is\", \"coding\"],\n","    [\"car\", \"is\", \"Tesla\"],\n","    [\"food\", \"likes\", \"biryani\"],\n","    [\"sport\", \"likes\", \"MMA\"]\n","]\n","# Repeat 30x ‚Üí 90 training steps, evenly mixed\n","sequence = base_facts * 30"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13,"status":"ok","timestamp":1766665556039,"user":{"displayName":"Fahad Zaman","userId":"16652441301219421491"},"user_tz":-300},"id":"C-XswmQ-StPv","outputId":"c5e518e7-36be-4140-d523-ba124b7eb15f"},"outputs":[{"name":"stdout","output_type":"stream","text":["üîç Checking vocabulary coverage...\n","\n","‚úÖ All words found in vocabulary!\n","\n"]}],"source":["# Check if all words in sequences are in vocab\n","print(\"üîç Checking vocabulary coverage...\\n\")\n","\n","all_words = set()\n","for seq in sequence:\n","    for word in seq:\n","        all_words.add(word)\n","\n","missing_words = []\n","for word in all_words:\n","    if word not in word2idx:\n","        missing_words.append(word)\n","\n","if missing_words:\n","    print(f\"‚ùå Missing words: {missing_words}\")\n","    print(f\"\\nCurrent vocab: {vocab}\")\n","else:\n","    print(\"‚úÖ All words found in vocabulary!\")\n","\n","print()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":129064,"status":"ok","timestamp":1766665687535,"user":{"displayName":"Fahad Zaman","userId":"16652441301219421491"},"user_tz":-300},"id":"vde-hj2UgNK4","outputId":"9b6aa629-808b-45a9-9249-6cd4a981cfcb"},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","Training MAC on sequences...\n","\n","Epoch 0: Loss = 301.3813\n","Epoch 40: Loss = 0.0076\n","Epoch 80: Loss = 0.0032\n","Epoch 120: Loss = 0.0022\n","Epoch 160: Loss = 0.0019\n","\n","‚úÖ Training complete!\n"]}],"source":["print(\"\\nTraining MAC on sequences...\\n\")\n","\n","mac = MAC_Layer()\n","optimizer = torch.optim.SGD(mac.parameters(), lr=0.05, weight_decay=0.0001)  # ‚Üê Lower LR + decay\n","\n","for epoch in range(200):  # More epochs with lower LR\n","    total_loss = 0\n","\n","    for seq in sequence:\n","        seq_vecs = torch.stack([word_to_vec(w).squeeze(0) for w in seq])\n","        output, attn_weights = mac(seq_vecs)\n","\n","        loss = 0\n","        for i in range(len(seq) - 1):\n","            pred = output[i]\n","            target = seq_vecs[i + 1]\n","            loss += (pred - target).pow(2).mean()\n","\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","\n","        total_loss += loss.item()\n","\n","    if epoch % 40 == 0:\n","        print(f\"Epoch {epoch}: Loss = {total_loss:.4f}\")\n","\n","print(\"\\n‚úÖ Training complete!\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":23,"status":"ok","timestamp":1766665724356,"user":{"displayName":"Fahad Zaman","userId":"16652441301219421491"},"user_tz":-300},"id":"2cfG50MAQ7nr","outputId":"61d4a0e0-4137-4287-b66c-f7e29c874bd6"},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","-----------TOKEN-BY-TOKEN GENERATION TEST:----------------\n","\n","‚úÖ 'user_name is' ‚Üí Expected: 'Fahad' | Got: 'Fahad'\n","‚úÖ 'pet_name is' ‚Üí Expected: 'Max' | Got: 'Max'\n","‚úÖ 'city is' ‚Üí Expected: 'Toronto' | Got: 'Toronto'\n","‚ùå 'job is' ‚Üí Expected: 'engineer' | Got: 'BMW'\n","‚úÖ 'favorite_color is' ‚Üí Expected: 'blue' | Got: 'blue'\n","‚úÖ 'age is' ‚Üí Expected: '23' | Got: '23'\n","‚ùå 'hobby is' ‚Üí Expected: 'coding' | Got: 'likes'\n","‚úÖ 'car is' ‚Üí Expected: 'Tesla' | Got: 'Tesla'\n","‚úÖ 'food likes' ‚Üí Expected: 'biryani' | Got: 'biryani'\n","‚ùå 'sport likes' ‚Üí Expected: 'MMA' | Got: 'car'\n","\n","Score: 7/10\n"]}],"source":["print(\"\\n-----------TOKEN-BY-TOKEN GENERATION TEST:----------------\\n\")\n","\n","tests = [\n","    ([\"user_name\", \"is\"], \"Fahad\"),\n","    ([\"pet_name\", \"is\"], \"Max\"),\n","    ([\"city\", \"is\"], \"Toronto\"),\n","    ([\"job\", \"is\"], \"engineer\"),\n","    ([\"favorite_color\", \"is\"], \"blue\"),\n","    ([\"age\", \"is\"], \"23\"),\n","    ([\"hobby\", \"is\"], \"coding\"),\n","    ([\"car\", \"is\"], \"Tesla\"),\n","    ([\"food\", \"likes\"], \"biryani\"),\n","    ([\"sport\", \"likes\"], \"MMA\")\n","]\n","\n","correct = 0\n","for query, expected in tests:\n","    query_vecs = torch.stack([word_to_vec(w).squeeze(0) for w in query])\n","    output, _ = mac(query_vecs)\n","    pred_word = vec_to_word(output[-1])\n","\n","    status = \"‚úÖ\" if pred_word == expected else \"‚ùå\"\n","    print(f\"{status} '{' '.join(query)}' ‚Üí Expected: '{expected}' | Got: '{pred_word}'\")\n","    if pred_word == expected:\n","        correct += 1\n","\n","print(f\"\\nScore: {correct}/10\")"]},{"cell_type":"markdown","metadata":{"id":"R6yFFREgWMbv"},"source":["#### **Flow of How all works**\n"]},{"cell_type":"markdown","metadata":{"id":"9UX3Nc5aWQ5H"},"source":["---\n","\n","## **What Each Part Does:**\n","\n","### **1. Vocabulary**\n","- List of all words the model knows\n","- Creates mappings: word ‚Üî number\n","\n","### **2. Embeddings (Frozen)**\n","- Converts each word into a vector of 16 numbers\n","- \"Frozen\" = these vectors don't change during training\n","- Like a dictionary: \"Fahad\" ‚Üí [0.2, -0.1, 0.8, ...]\n","\n","### **3. LMM (Long-Term Memory)**\n","- A small neural network (2 layers)\n","- Takes a 16-number vector IN\n","- Outputs a 16-number vector OUT\n","- **Its job:** Learn to map questions ‚Üí answers\n","- Example: \"pet_name\" ‚Üí \"Max\"\n","\n","### **4. Attention**\n","- Compares tokens to each other\n","- Decides which tokens are important\n","- Creates weighted combinations\n","- **Its job:** \"Which past tokens should I focus on?\"\n","\n","### **5. MAC Layer**\n","- **Combines LMM + Attention**\n","- For each token:\n","  - Get memory summary from LMM\n","  - Combine original token + memory summary\n","  - Use attention to decide: use memory or not?\n","\n","### **6. Training Loop**\n","- Processes sequences: [\"user_name\", \"is\", \"Fahad\"]\n","- At each position, tries to predict the NEXT word\n","- Position 0: See \"user_name\" ‚Üí predict \"is\"\n","- Position 1: See \"user_name is\" ‚Üí predict \"Fahad\"\n","- Calculates error (loss)\n","- Updates LMM and Attention weights to reduce error\n","\n","### **7. Testing**\n","- After training, ask: \"pet_name\" ‚Üí what's the answer?\n","- MAC uses both memory and attention to respond\n","\n","---\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"Jgd1baM7Q7tI"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2ROQSGUnQ7vs"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":9264,"status":"aborted","timestamp":1766753202171,"user":{"displayName":"Fahad Zaman","userId":"16652441301219421491"},"user_tz":-300},"id":"u_FdMoosdM8s"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":["MEd4B_ZKKi12"],"gpuType":"T4","name":"","provenance":[{"file_id":"1t_B-7n3K3UTvzkHTgoAPK4DcWY-lhGXz","timestamp":1766648235853}],"version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}